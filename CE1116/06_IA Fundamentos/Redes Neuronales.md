# **Redes Neuronales**

Una red neuronal es un modelo computacional inspirado en el cerebro humano, pero basado en funciones matemáticas. Está compuesta por neuronas artificiales organizadas en capas (entrada, ocultas y salida), conectadas mediante pesos y sesgos que se ajustan en el entrenamiento. El aprendizaje ocurre mediante algoritmos como backpropagation y descenso de gradiente, que optimizan una función de costo.
Las funciones de activación introducen no linealidad, lo que permite que la red aprenda relaciones complejas. Para procesar datos como texto o imágenes, se emplean embeddings, que transforman la información en vectores numéricos significativos. Existen diversas arquitecturas: las CNNs destacan en visión por computadora, mientras que los Transformers son la base de los modelos de lenguaje modernos por su capacidad de manejar dependencias largas y entrenarse de forma altamente paralelizada.
Finalmente, el desempeño de una red depende también de los hiperparámetros (número de capas, tasa de aprendizaje, tamaño de batch, etc.), y en arquitecturas como los Transformers se incorpora el positional encoding para preservar el orden en las secuencias.

## 📚 Idea/Concepto

Modelo computacional inspirado en la estructura del cerebro humano, compuesto por capas de nodos (neuronas artificiales) conectados entre sí, que procesan información mediante funciones de activación y ajuste de pesos.

## 📌 Puntos Claves (Opcional)

- Se entrenan ajustando los pesos para minimizar el error.
- Pueden ser feedforward o recurrentes.
- Base de arquitecturas modernas como CNNs y Transformers.

## 🔗 Connections

- [[Large Language Models (LLMs)]]
- [[Embeddings]]
